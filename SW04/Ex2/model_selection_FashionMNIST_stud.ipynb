{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ec37d7-f7cb-4646-a2dd-9dab66239a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8a986-1cb2-483b-9bd8-0f71d69fa9e8",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba6b0c6-3f55-40dd-ba32-6f6aad8f1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.mnist.FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.mnist.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2da4ed-af9a-4fc7-b59f-135b51241d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data, validation_data = torch.utils.data.random_split(training_data, [50000, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b30c81-d89f-4947-aa09-ab8c70dd262c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data),len(validation_data),len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ff404-5b8a-4f63-9730-d6708d2ac8d1",
   "metadata": {},
   "source": [
    "### MLP with Dropout Regularisation\n",
    "\n",
    "Use different dropout rates for the input layer (`p_in`) and hidden layers (`p_hidden`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61b15df-a84b-483d-9365-d8f66390b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4bfd0a4-999c-4690-9ef3-b5ee1ab26c30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                  [-1, 784]               0\n",
      "           Dropout-2                  [-1, 784]               0\n",
      "            Linear-3                  [-1, 200]         157,000\n",
      "           Dropout-4                  [-1, 200]               0\n",
      "           Sigmoid-5                  [-1, 200]               0\n",
      "            Linear-6                   [-1, 10]           2,010\n",
      "================================================================\n",
      "Total params: 159,010\n",
      "Trainable params: 159,010\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.61\n",
      "Estimated Total Size (MB): 0.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ...\n",
    "\n",
    "from torchsummary import summary\n",
    "summary(model, (1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa393a-9f99-48f4-996d-cf8d2a3b8cd5",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Implement the training / evaluation loop\n",
    "\n",
    "Remember and return training / validation cost and accuracy per epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "172c91d1-4c9e-413a-bfff-01f51a1e323a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_eval(model, lr, nepochs, nbatch, training_data, validation_data):\n",
    "    \n",
    "\n",
    "    ...\n",
    "    \n",
    "    return cost_hist, cost_hist_test, acc_hist, acc_hist_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625a52b-a332-4844-8d7d-6998893a2d70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Analyse Different Settings\n",
    "\n",
    "Start with a baseline model: 200 units in a single hidden layer; batch size 64; properly tuned learning rate, no dropout.\n",
    "\n",
    "Then play with different model complexities and dropout rates and compare them on the basis of the validation set.\n",
    "\n",
    "Estimate also the variance error by the difference between validation and training loss / accuracy.\n",
    "\n",
    "Finally, identify a favourite combination (model complexity, dropout rate) and compute the test accuracy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a1fa1c2b-50d7-4b23-91c8-c47eec5fc8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########\n",
      "CONFIG:  [784, 250, 80, 10] (0.0, 0.0)\n",
      "########\n",
      "Epoch 0: 1.235250, 0.576533, 0.512870, 0.844100\n",
      "Epoch 1: 0.401204, 0.883483, 0.341219, 0.898700\n",
      "Epoch 2: 0.313341, 0.908567, 0.283342, 0.918100\n",
      "Epoch 3: 0.261595, 0.923783, 0.265291, 0.922500\n",
      "Epoch 4: 0.223723, 0.933883, 0.222232, 0.932700\n",
      "Epoch 5: 0.193600, 0.942667, 0.186735, 0.945000\n",
      "Epoch 6: 0.171056, 0.950067, 0.168389, 0.947000\n",
      "Epoch 7: 0.152257, 0.955400, 0.159610, 0.951500\n",
      "Epoch 8: 0.137581, 0.959667, 0.136814, 0.958900\n",
      "Epoch 9: 0.124340, 0.963267, 0.133521, 0.960000\n",
      "Epoch 10: 0.113409, 0.966933, 0.133800, 0.959400\n",
      "Epoch 11: 0.103520, 0.969517, 0.123681, 0.963100\n",
      "Epoch 12: 0.095432, 0.971867, 0.112063, 0.964100\n",
      "Epoch 13: 0.088115, 0.974383, 0.106945, 0.966800\n",
      "Epoch 14: 0.081437, 0.976567, 0.102911, 0.968700\n",
      "Epoch 15: 0.076218, 0.977650, 0.097051, 0.969800\n",
      "Epoch 16: 0.070842, 0.979517, 0.093090, 0.970300\n",
      "Epoch 17: 0.065727, 0.980683, 0.090868, 0.972000\n",
      "Epoch 18: 0.061402, 0.982317, 0.085151, 0.972800\n",
      "Epoch 19: 0.057978, 0.983117, 0.085043, 0.974100\n",
      "Epoch 20: 0.054260, 0.983567, 0.091885, 0.970500\n",
      "Epoch 21: 0.050596, 0.986050, 0.082790, 0.973700\n",
      "Epoch 22: 0.047546, 0.986367, 0.083843, 0.974500\n",
      "Epoch 23: 0.044551, 0.987100, 0.081467, 0.974300\n",
      "Epoch 24: 0.041294, 0.988750, 0.079027, 0.975800\n",
      "Epoch 25: 0.038929, 0.989083, 0.079541, 0.975200\n",
      "Epoch 26: 0.036434, 0.990050, 0.078820, 0.975000\n",
      "Epoch 27: 0.033970, 0.990550, 0.073514, 0.978100\n",
      "Epoch 28: 0.031643, 0.991500, 0.072228, 0.978000\n",
      "Epoch 29: 0.029613, 0.992000, 0.074483, 0.977600\n",
      "Epoch 30: 0.028152, 0.992317, 0.072536, 0.978000\n",
      "Epoch 31: 0.025843, 0.993467, 0.075263, 0.976900\n",
      "Epoch 32: 0.024488, 0.993850, 0.071519, 0.978700\n",
      "Epoch 33: 0.022990, 0.994267, 0.071484, 0.978200\n",
      "Epoch 34: 0.021063, 0.995533, 0.071767, 0.978000\n",
      "Epoch 35: 0.019488, 0.995950, 0.071431, 0.979200\n",
      "Epoch 36: 0.018185, 0.996217, 0.072256, 0.978400\n",
      "Epoch 37: 0.017213, 0.996433, 0.072117, 0.978500\n",
      "Epoch 38: 0.016070, 0.996817, 0.071519, 0.979000\n",
      "Epoch 39: 0.015085, 0.997067, 0.071682, 0.979200\n",
      "Epoch 40: 0.014007, 0.997600, 0.071156, 0.979800\n",
      "Epoch 41: 0.013119, 0.997817, 0.072449, 0.978900\n",
      "Epoch 42: 0.012153, 0.998083, 0.073255, 0.978600\n",
      "Epoch 43: 0.011517, 0.998467, 0.071948, 0.978900\n",
      "Epoch 44: 0.010523, 0.998767, 0.074733, 0.978600\n",
      "Epoch 45: 0.010123, 0.998600, 0.073532, 0.979100\n",
      "Epoch 46: 0.009426, 0.998950, 0.072451, 0.978900\n",
      "Epoch 47: 0.008884, 0.998950, 0.072300, 0.979900\n",
      "Epoch 48: 0.008214, 0.999167, 0.075405, 0.978500\n",
      "Epoch 49: 0.007890, 0.999233, 0.073502, 0.979500\n",
      "########\n",
      "CONFIG:  [784, 250, 80, 10] (0.0, 0.25)\n",
      "########\n",
      "Epoch 0: 1.321211, 0.544450, 0.505403, 0.847200\n",
      "Epoch 1: 0.434023, 0.874233, 0.398220, 0.876000\n",
      "Epoch 2: 0.339460, 0.900667, 0.292253, 0.916200\n",
      "Epoch 3: 0.291890, 0.915333, 0.270024, 0.921700\n",
      "Epoch 4: 0.258427, 0.924200, 0.245984, 0.928800\n",
      "Epoch 5: 0.230629, 0.932500, 0.233694, 0.930600\n",
      "Epoch 6: 0.212046, 0.937900, 0.207893, 0.937800\n",
      "Epoch 7: 0.196400, 0.941700, 0.176003, 0.947900\n",
      "Epoch 8: 0.181858, 0.946567, 0.168894, 0.949300\n",
      "Epoch 9: 0.170395, 0.949417, 0.174393, 0.947700\n",
      "Epoch 10: 0.160552, 0.951633, 0.167889, 0.949700\n",
      "Epoch 11: 0.153104, 0.953933, 0.153662, 0.952600\n",
      "Epoch 12: 0.143640, 0.957217, 0.171030, 0.948300\n",
      "Epoch 13: 0.140050, 0.957867, 0.152635, 0.953800\n",
      "Epoch 14: 0.133354, 0.959800, 0.128250, 0.960600\n",
      "Epoch 15: 0.128691, 0.960750, 0.148048, 0.954300\n",
      "Epoch 16: 0.123266, 0.962633, 0.128626, 0.961700\n",
      "Epoch 17: 0.119163, 0.964017, 0.140168, 0.957300\n",
      "Epoch 18: 0.112883, 0.965750, 0.124920, 0.962700\n",
      "Epoch 19: 0.109981, 0.966450, 0.174667, 0.947200\n",
      "Epoch 20: 0.106019, 0.967950, 0.115254, 0.964800\n",
      "Epoch 21: 0.103829, 0.967783, 0.131595, 0.960100\n",
      "Epoch 22: 0.102896, 0.967567, 0.117028, 0.965600\n",
      "Epoch 23: 0.097576, 0.969733, 0.122056, 0.963900\n",
      "Epoch 24: 0.093495, 0.970783, 0.119576, 0.964100\n",
      "Epoch 25: 0.092796, 0.971767, 0.099564, 0.971200\n",
      "Epoch 26: 0.091592, 0.971117, 0.109473, 0.967400\n",
      "Epoch 27: 0.090314, 0.971783, 0.114871, 0.965700\n",
      "Epoch 28: 0.086752, 0.972333, 0.103953, 0.968200\n",
      "Epoch 29: 0.085772, 0.971617, 0.104149, 0.969400\n",
      "Epoch 30: 0.081889, 0.973583, 0.103293, 0.969600\n",
      "Epoch 31: 0.082052, 0.973983, 0.094571, 0.971800\n",
      "Epoch 32: 0.080765, 0.974517, 0.094304, 0.972500\n",
      "Epoch 33: 0.075857, 0.976233, 0.101077, 0.970000\n",
      "Epoch 34: 0.075971, 0.975750, 0.104889, 0.969100\n",
      "Epoch 35: 0.073871, 0.977133, 0.100174, 0.971000\n",
      "Epoch 36: 0.073141, 0.976500, 0.105724, 0.969100\n",
      "Epoch 37: 0.071952, 0.977100, 0.133542, 0.962300\n",
      "Epoch 38: 0.070654, 0.977300, 0.089544, 0.972800\n",
      "Epoch 39: 0.068757, 0.978267, 0.090076, 0.973600\n",
      "Epoch 40: 0.067932, 0.978417, 0.082228, 0.976000\n",
      "Epoch 41: 0.064990, 0.978650, 0.104232, 0.969200\n",
      "Epoch 42: 0.064644, 0.979417, 0.085466, 0.975800\n",
      "Epoch 43: 0.063987, 0.979850, 0.096461, 0.972900\n",
      "Epoch 44: 0.062028, 0.980517, 0.100650, 0.970800\n",
      "Epoch 45: 0.062722, 0.980233, 0.096926, 0.972000\n",
      "Epoch 46: 0.063080, 0.979733, 0.093015, 0.974900\n",
      "Epoch 47: 0.060934, 0.980050, 0.098695, 0.971800\n",
      "Epoch 48: 0.058741, 0.980817, 0.100226, 0.970400\n",
      "Epoch 49: 0.058298, 0.980800, 0.092411, 0.974100\n",
      "########\n",
      "CONFIG:  [784, 250, 80, 10] (0.0, 0.5)\n",
      "########\n",
      "Epoch 0: 1.439778, 0.506983, 0.570411, 0.811000\n",
      "Epoch 1: 0.507163, 0.854783, 0.375261, 0.893300\n",
      "Epoch 2: 0.384845, 0.889033, 0.344949, 0.911400\n",
      "Epoch 3: 0.337007, 0.904017, 0.367372, 0.904800\n",
      "Epoch 4: 0.303239, 0.913600, 0.357355, 0.910000\n",
      "Epoch 5: 0.276093, 0.920883, 0.348312, 0.912600\n",
      "Epoch 6: 0.257922, 0.926117, 0.315530, 0.923000\n",
      "Epoch 7: 0.242149, 0.930433, 0.309438, 0.922700\n",
      "Epoch 8: 0.227074, 0.934217, 0.303927, 0.926000\n",
      "Epoch 9: 0.219375, 0.936617, 0.268881, 0.934900\n",
      "Epoch 10: 0.211113, 0.939200, 0.288079, 0.930000\n",
      "Epoch 11: 0.203961, 0.940200, 0.295052, 0.929200\n",
      "Epoch 12: 0.193271, 0.942633, 0.279505, 0.931600\n",
      "Epoch 13: 0.188575, 0.944200, 0.312040, 0.925500\n",
      "Epoch 14: 0.185481, 0.945400, 0.296379, 0.928700\n",
      "Epoch 15: 0.178665, 0.947467, 0.264274, 0.935500\n",
      "Epoch 16: 0.171416, 0.949667, 0.277808, 0.935300\n",
      "Epoch 17: 0.169067, 0.950067, 0.270674, 0.934000\n",
      "Epoch 18: 0.164893, 0.952733, 0.307052, 0.927500\n",
      "Epoch 19: 0.159220, 0.952967, 0.307923, 0.926900\n",
      "Epoch 20: 0.158780, 0.952967, 0.270161, 0.935200\n",
      "Epoch 21: 0.153081, 0.954500, 0.257022, 0.939500\n",
      "Epoch 22: 0.152644, 0.955333, 0.261545, 0.939500\n",
      "Epoch 23: 0.148264, 0.955683, 0.272107, 0.935100\n",
      "Epoch 24: 0.144750, 0.957317, 0.293673, 0.930300\n",
      "Epoch 25: 0.143768, 0.957283, 0.262162, 0.939900\n",
      "Epoch 26: 0.140569, 0.958267, 0.273660, 0.936000\n",
      "Epoch 27: 0.139683, 0.958033, 0.207503, 0.952000\n",
      "Epoch 28: 0.136028, 0.959000, 0.268163, 0.938300\n",
      "Epoch 29: 0.135428, 0.959167, 0.234873, 0.946500\n",
      "Epoch 30: 0.133737, 0.960233, 0.248208, 0.942800\n",
      "Epoch 31: 0.132915, 0.960233, 0.251373, 0.944300\n",
      "Epoch 32: 0.129688, 0.960967, 0.226355, 0.950500\n",
      "Epoch 33: 0.128315, 0.961633, 0.283488, 0.936800\n",
      "Epoch 34: 0.126725, 0.961267, 0.248569, 0.942900\n",
      "Epoch 35: 0.126419, 0.961583, 0.239346, 0.945200\n",
      "Epoch 36: 0.126992, 0.961650, 0.217128, 0.950300\n",
      "Epoch 37: 0.124123, 0.962367, 0.231768, 0.948400\n",
      "Epoch 38: 0.123123, 0.962800, 0.281446, 0.937200\n",
      "Epoch 39: 0.121092, 0.963450, 0.255688, 0.943200\n",
      "Epoch 40: 0.120567, 0.963483, 0.230029, 0.949700\n",
      "Epoch 41: 0.119559, 0.963817, 0.195285, 0.955900\n",
      "Epoch 42: 0.116172, 0.964267, 0.256012, 0.943300\n",
      "Epoch 43: 0.118928, 0.964217, 0.298319, 0.935100\n",
      "Epoch 44: 0.115053, 0.965300, 0.234906, 0.948400\n",
      "Epoch 45: 0.112342, 0.966467, 0.238759, 0.946900\n",
      "Epoch 46: 0.108307, 0.967133, 0.220482, 0.952100\n",
      "Epoch 47: 0.115633, 0.965500, 0.307937, 0.932900\n",
      "Epoch 48: 0.111657, 0.965850, 0.235623, 0.949700\n",
      "Epoch 49: 0.109991, 0.966800, 0.211839, 0.952800\n",
      "########\n",
      "CONFIG:  [784, 250, 80, 10] (0.2, 0.5)\n",
      "########\n",
      "Epoch 0: 1.469045, 0.495233, 0.556581, 0.820000\n",
      "Epoch 1: 0.541498, 0.838767, 0.382004, 0.892000\n",
      "Epoch 2: 0.429042, 0.872100, 0.402652, 0.893700\n",
      "Epoch 3: 0.378112, 0.889783, 0.355398, 0.909100\n",
      "Epoch 4: 0.343196, 0.898983, 0.354554, 0.913000\n",
      "Epoch 5: 0.314634, 0.907783, 0.357635, 0.910500\n",
      "Epoch 6: 0.294548, 0.912633, 0.311256, 0.923100\n",
      "Epoch 7: 0.280245, 0.918383, 0.377993, 0.908900\n",
      "Epoch 8: 0.267986, 0.921783, 0.355951, 0.911300\n",
      "Epoch 9: 0.262795, 0.923000, 0.355299, 0.912700\n",
      "Epoch 10: 0.247611, 0.926883, 0.324632, 0.921800\n",
      "Epoch 11: 0.240375, 0.927533, 0.325245, 0.918700\n",
      "Epoch 12: 0.232981, 0.931967, 0.296375, 0.927100\n",
      "Epoch 13: 0.223941, 0.933217, 0.275182, 0.932800\n",
      "Epoch 14: 0.221735, 0.934783, 0.319809, 0.924800\n",
      "Epoch 15: 0.219822, 0.935917, 0.357574, 0.914800\n",
      "Epoch 16: 0.215022, 0.936017, 0.323236, 0.924300\n",
      "Epoch 17: 0.210696, 0.938233, 0.264256, 0.938400\n",
      "Epoch 18: 0.202594, 0.938933, 0.348804, 0.918200\n",
      "Epoch 19: 0.203653, 0.938783, 0.290104, 0.932300\n",
      "Epoch 20: 0.197812, 0.940683, 0.259662, 0.937000\n",
      "Epoch 21: 0.198880, 0.941283, 0.321060, 0.924800\n",
      "Epoch 22: 0.194774, 0.941383, 0.364018, 0.916300\n",
      "Epoch 23: 0.192518, 0.942817, 0.275128, 0.936900\n",
      "Epoch 24: 0.186023, 0.944383, 0.282331, 0.935700\n",
      "Epoch 25: 0.186007, 0.945183, 0.313112, 0.927500\n",
      "Epoch 26: 0.186456, 0.944950, 0.254702, 0.940100\n",
      "Epoch 27: 0.181830, 0.945600, 0.230537, 0.946300\n",
      "Epoch 28: 0.178213, 0.946067, 0.311253, 0.928700\n",
      "Epoch 29: 0.179942, 0.945767, 0.285143, 0.933900\n",
      "Epoch 30: 0.175670, 0.947917, 0.272168, 0.938400\n",
      "Epoch 31: 0.174294, 0.948050, 0.258811, 0.939900\n",
      "Epoch 32: 0.172947, 0.948717, 0.261621, 0.941000\n",
      "Epoch 33: 0.171464, 0.948950, 0.312847, 0.929400\n",
      "Epoch 34: 0.169299, 0.949800, 0.266268, 0.940300\n",
      "Epoch 35: 0.168208, 0.949700, 0.253927, 0.943100\n",
      "Epoch 36: 0.169458, 0.949950, 0.280331, 0.938800\n",
      "Epoch 37: 0.165977, 0.950317, 0.306109, 0.932100\n",
      "Epoch 38: 0.164972, 0.949617, 0.271755, 0.938800\n",
      "Epoch 39: 0.166565, 0.950833, 0.289069, 0.935700\n",
      "Epoch 40: 0.162414, 0.950983, 0.253749, 0.943100\n",
      "Epoch 41: 0.163528, 0.951633, 0.253343, 0.944500\n",
      "Epoch 42: 0.161251, 0.952683, 0.252010, 0.945300\n",
      "Epoch 43: 0.163121, 0.951683, 0.243911, 0.947300\n",
      "Epoch 44: 0.156909, 0.953017, 0.265653, 0.940200\n",
      "Epoch 45: 0.157041, 0.952633, 0.280883, 0.937400\n",
      "Epoch 46: 0.160365, 0.951650, 0.239184, 0.946500\n",
      "Epoch 47: 0.156339, 0.954100, 0.283481, 0.936800\n",
      "Epoch 48: 0.158489, 0.953400, 0.224200, 0.949200\n",
      "Epoch 49: 0.154032, 0.954000, 0.275486, 0.938800\n",
      "########\n",
      "CONFIG:  [784, 250, 80, 10] (0.4, 0.75)\n",
      "########\n",
      "Epoch 0: 1.919876, 0.304700, 1.018899, 0.575600\n",
      "Epoch 1: 1.051710, 0.651867, 0.755729, 0.791100\n",
      "Epoch 2: 0.809799, 0.748650, 0.680612, 0.859500\n",
      "Epoch 3: 0.719598, 0.780950, 0.713684, 0.866600\n",
      "Epoch 4: 0.675428, 0.798583, 0.752197, 0.875400\n",
      "Epoch 5: 0.643722, 0.809017, 0.766972, 0.881900\n",
      "Epoch 6: 0.631608, 0.814250, 0.722651, 0.893100\n",
      "Epoch 7: 0.610954, 0.820900, 0.836073, 0.883500\n",
      "Epoch 8: 0.598273, 0.825417, 0.757931, 0.900000\n",
      "Epoch 9: 0.592164, 0.829733, 0.890470, 0.880600\n",
      "Epoch 10: 0.583795, 0.832767, 0.872276, 0.884900\n",
      "Epoch 11: 0.575319, 0.834117, 0.842012, 0.892500\n",
      "Epoch 12: 0.564676, 0.837633, 0.865333, 0.892200\n",
      "Epoch 13: 0.556232, 0.840350, 0.878066, 0.891600\n",
      "Epoch 14: 0.554164, 0.839183, 0.845869, 0.895300\n",
      "Epoch 15: 0.550754, 0.840517, 0.770117, 0.906800\n",
      "Epoch 16: 0.548316, 0.843933, 0.915120, 0.889400\n",
      "Epoch 17: 0.546615, 0.844383, 0.881009, 0.895700\n",
      "Epoch 18: 0.540269, 0.845533, 0.810042, 0.903600\n",
      "Epoch 19: 0.536859, 0.847550, 0.780396, 0.908700\n",
      "Epoch 20: 0.530565, 0.849550, 0.841125, 0.900500\n",
      "Epoch 21: 0.533506, 0.848867, 0.903177, 0.893800\n",
      "Epoch 22: 0.526803, 0.850917, 0.809502, 0.906200\n",
      "Epoch 23: 0.527180, 0.849867, 0.880865, 0.898100\n",
      "Epoch 24: 0.526016, 0.850983, 0.844613, 0.901500\n",
      "Epoch 25: 0.526159, 0.851483, 0.822979, 0.904900\n",
      "Epoch 26: 0.514828, 0.854933, 0.867297, 0.899500\n",
      "Epoch 27: 0.520120, 0.852633, 0.834513, 0.904500\n",
      "Epoch 28: 0.519280, 0.853633, 0.855974, 0.902200\n",
      "Epoch 29: 0.514411, 0.855867, 0.843498, 0.904000\n",
      "Epoch 30: 0.500658, 0.858067, 0.869123, 0.901500\n",
      "Epoch 31: 0.503315, 0.858400, 0.805901, 0.910000\n",
      "Epoch 32: 0.509331, 0.854233, 0.841924, 0.902700\n",
      "Epoch 33: 0.507182, 0.857517, 0.798273, 0.910300\n",
      "Epoch 34: 0.508897, 0.857067, 0.870330, 0.901300\n",
      "Epoch 35: 0.506879, 0.856517, 0.851319, 0.903900\n",
      "Epoch 36: 0.504092, 0.859783, 0.838686, 0.904900\n",
      "Epoch 37: 0.501809, 0.858167, 0.753697, 0.915000\n",
      "Epoch 38: 0.497977, 0.858900, 0.901327, 0.899400\n",
      "Epoch 39: 0.500271, 0.858183, 0.834872, 0.906600\n",
      "Epoch 40: 0.499733, 0.858967, 0.827693, 0.908500\n",
      "Epoch 41: 0.495192, 0.860350, 0.823777, 0.909600\n",
      "Epoch 42: 0.496030, 0.860900, 0.889149, 0.899900\n",
      "Epoch 43: 0.487471, 0.863800, 0.783547, 0.911500\n",
      "Epoch 44: 0.491103, 0.861417, 0.774180, 0.914300\n",
      "Epoch 45: 0.488498, 0.863100, 0.836035, 0.909000\n",
      "Epoch 46: 0.490152, 0.862750, 0.793756, 0.911500\n",
      "Epoch 47: 0.491179, 0.861750, 0.826183, 0.909100\n",
      "Epoch 48: 0.494085, 0.860917, 0.811965, 0.912100\n",
      "Epoch 49: 0.491117, 0.862417, 0.808697, 0.909300\n"
     ]
    }
   ],
   "source": [
    "nbatch = 64\n",
    "nepochs = 50\n",
    "lr = 0.25\n",
    "\n",
    "complexity = ...\n",
    "drop_p = ...\n",
    "\n",
    "costs = {\"train\":[],\"test\":[]}\n",
    "accs =  {\"train\":[],\"test\":[]}\n",
    "\n",
    "for p in drop_p:\n",
    "    print(\"########\")\n",
    "    print(\"CONFIG: \", config, p)\n",
    "    print(\"########\")\n",
    "\n",
    "    model = ... # model with given complexity and dropout\n",
    "\n",
    "    cost_hist, cost_hist_test, acc_hist, acc_hist_test = train_eval(model, lr, nepochs, nbatch, training_data, validation_data)\n",
    "    costs[\"train\"].append(cost_hist)    \n",
    "    costs[\"test\"].append(cost_hist_test)\n",
    "    accs[\"train\"].append(acc_hist)    \n",
    "    accs[\"test\"].append(acc_hist_test)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b7ada-69f8-4531-9dc7-06cf0573284c",
   "metadata": {},
   "source": [
    "### Suitable Output Plots\n",
    "\n",
    "Possibly adjust to fit your needs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9077b7-8b2b-429b-b5c4-c024f1daadf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"b--\",\"r--\",\"m--\",\"g--\",\"y--\"]\n",
    "colors_test = [\"b-\",\"r-\",\"m-\",\"g-\",\"y-\"]\n",
    "plt.figure(1, figsize=(12,8))\n",
    "for i in range(len(drop_p)):\n",
    "    plt.plot(torch.arange(nepochs), costs[\"train\"][i], colors[i], label=\"train \"+str(drop_p[i]))\n",
    "    plt.plot(torch.arange(nepochs), costs[\"test\"][i], colors_test[i], label=\"test \"+str(drop_p[i]))\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.xlim(0,nepochs)\n",
    "plt.ylim(0,0.5)\n",
    "plt.title(\"Cross-Entropy Cost\", fontsize=18)\n",
    "plt.legend(bbox_to_anchor = (1.05, 0.6))\n",
    "plt.figure(2, figsize=(12,8))\n",
    "for i in range(len(drop_p)):\n",
    "    acc = np.array(accs[\"train\"][i])\n",
    "    acc_test = np.array(accs[\"test\"][i])\n",
    "    plt.plot(torch.arange(nepochs), acc, colors[i], label=\"train \"+str(drop_p[i]))\n",
    "    plt.plot(torch.arange(nepochs), acc_test, colors_test[i], label=\"test \"+str(drop_p[i]))\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.xlim(0,nepochs)\n",
    "plt.ylim(0.9,1.0)\n",
    "plt.title(\"Accuracy\", fontsize=18)\n",
    "plt.legend(bbox_to_anchor = (1.05, 0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0bef3-7aeb-4329-aa64-e8d107c9bee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
